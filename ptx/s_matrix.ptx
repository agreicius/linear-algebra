<section xml:id="s_matrix">
  <title>Matrices</title>
  <introduction>
    <p>
      Matrices played a small supporting role in our discussion of linear systems in <xref ref="c_linear_systems"/>. In this chapter we bring them to center stage and give them a full-blown treatment as independent mathematical objects in their own right.
    </p>
    <p>Like any mathematical object worth its salt, matrices can be employed in a vast multitude of ways. As such it is important to allow matrices to transcend their humble beginnings in this course as boiled down systems of linear equations. We record this observation as an official principle.

      <principle xml:id="princ_matrix_mantra">
        <title>Matrix mantra</title>
        <statement>
          <p>
          A matrix is a matrix is a matrix.
          </p>
          <p>
          Not every matrix should be thought of as an augmented matrix associated to a linear system.
          </p>
        </statement>
      </principle>
    </p>
  </introduction>
  <subsection xml:id="ss_matrix_attributes">
    <title>Basic attributes</title>
    As the next definition makes clear, a matrix is just an ordered sequence of numbers arranged in a very particular manner.
    <definition xml:id="d_matrix">
      <title>Matrix</title>
      <statement>
        <p>
        A <term>(real) matrix</term> is a rectangular array of real numbers
        <men xml:id="s_matrix_eq_matrix">
          A=\genmatrix
        </men>.
        The number <m>a_{ij}</m> located in the <m>i</m>-th row and <m>j</m>-th column of <m>A</m> is called the <term><m>(i,j)</m>-entry</term> (or <term><m>ij</m>-th entry</term>) of <m>A</m>.
        </p>
        <p>
          A matrix with <m>m</m> rows and <m>n</m> columns is said to have <term>size</term> (or <term>dimension</term>) <m>m\times n</m>.
        </p>
        <p>
          We will typically use capital letters near the beginning of the alphabet (<eg /> <m>A, B,C, D</m>, <etc />) to denote matrices.
        </p>
      </statement>
    </definition>
  <p>
  The displayed matrix in <xref ref="s_matrix_eq_matrix"/> is costly both in the space it takes up in print, and the time it takes to write down or typeset. Accordingly we introduce two somewhat complementary forms of notation to help describe matrices.
</p>
<definition xml:id="d_matrix_notation">
  <notation>
    <usage>[a_{ij}]_{m\times n}</usage>
    <description>Matrix whose <m>ij</m>-th entry is <m>a_{ij}</m></description>
  </notation>
  <notation>
    <usage>(A)_{ij}</usage>
    <description><m>ij</m>-th entry of the matrix <m>A</m></description>
  </notation>
  <statement>
    <dl>
      <li>
        <title>Matrix-building notation</title>
        <p>
          The notation <m>[a_{ij}]_{m\times n}</m> denotes the
          <m>m\times n</m> matrix whose <m>ij</m>-th entry (<m>i</m>-th row, <m>j</m>-th column) is <m>a_{ij}</m>. When there is no danger of confusion, this notation is often shortened to <m>[a_{ij}]</m>.
        </p>
      </li>
      <li>
        <title>Matrix entry notation</title>
        <p>
          Given a matrix <m>A</m>,
          the notation <m>(A)_{ij}</m> denotes the <m>ij</m>-th entry of <m>A</m>.
        </p>
      </li>
    </dl>
    <p>
      Thus if <m>A=[a_{ij}]_{m\times n}</m>, then <m>(A)_{ij}=a_{ij}</m> for all <m>1\leq i\leq m</m> and <m>1\leq j\leq n</m>.
    </p>
  </statement>
</definition>
<remark>
  <statement>
    <p>
      The matrix-building notation is often used simply to give names to the entries of an arbitrary matrix. However, it can also be used to describe a matrix whose <m>ij</m>-th entry is given by specified rule or formula.
    </p>
    <p>
      For example, let <m>A=[a_{ij}]_{2\times 3}</m>, where <m>a_{ij}=(i-j)j</m>. This is the <m>2\times 3</m> matrix whose <m>ij</m>-th entry is <m>(i-j)j</m>. Thus
      <me>
        A=\begin{bmatrix}(1-1)1 \amp (1-2)2 \amp (1-3)3\\ (2-1)1 \amp (2-2)2 \amp (2-3)3
      \end{bmatrix}=\begin{bmatrix}0 \amp -2 \amp -6\\ 1 \amp 0 \amp -3 \end{bmatrix}
      </me>.
      In this example we have <m>(A)_{23}=-3</m> and <m>(A)_{ii}=0</m> for <m>i=1,2</m>.
    </p>
  </statement>
</remark>
When introducing a new family of mathematical objects we always have
</subsection>
  <paragraphs>
    <title>Specially sized matrices</title>
    <p>
      An <m>n\times n</m> matrix is called a
      <term>square matrix of order <m>n</m></term>.
      <me>
        A=\varmatrix{n}{n}{a}
      </me>.
    </p>
    <p>
      A <m>1\times n</m> matrix is called a <term>row vector</term>:
      <me>
        \mathbf{a}=\begin{bmatrix}a_1\amp a_2\amp \cdots \amp a_n \end{bmatrix}
      </me>.
    </p>
    <p>
      An <m>m\times 1</m> matrix is called a
      <term>column vector</term>:
      <me>
        \mathbf{b}=\begin{bmatrix}b_1\\ b_2\\\vdots \\ b_m \end{bmatrix}
      </me>
    </p>
  </paragraphs>
  <paragraphs>
    <title>Equality, sum, difference</title>
    <definition>
      <statement>
        <p>
          Two matrices <m>A</m> and <m>B</m> are <term>equal</term> when
          <ol>
            <li>
              <p>
                they have the same size, and
              </p>
            </li>
            <li>
              <p>
                their corresponding entries are equal.
              </p>
            </li>
          </ol>
        </p>
        <p>
          In other words,
          <m>A</m> and <m>B</m> must both be <m>m\times n</m> matrices,
          and <m>(A)_{ij}=(B)_{ij}</m> for all
          <m>1\leq i\leq m</m> and <m>1\leq j\leq n</m>.
        </p>
      </statement>
    </definition>

    <definition>
      <statement>
        <p>
          Suppose <m>A=[a_{ij}]</m> and
          <m>B=[b_{ij}]</m> are both <m>m\times n</m> matrices.
          We define
          <ul>
            <li>
              <p>
                their <term>sum</term> <m>A+B</m> to be the matrix <m>C=[a_{ij}+b_{ij}]</m>;
              </p>
            </li>
            <li>
              <p>
                their <term>difference</term> <m>A-B</m> to be the matrix <m>D=[a_{ij}-b_{ij}]</m>.
              </p>
            </li>
          </ul>
        </p>
        <p>
          Equivalently,
          <m>A+B</m> and <m>A-B</m> are defined by declaring:
          <md>
            <mrow>(A+B)_{ij}\amp =\amp (A)_{ij}+(B)_{ij}</mrow>
            <mrow>(A-B)_{ij}\amp =\amp (A)_{ij}-B_{ij}</mrow>
          </md>
        </p>
      </statement>
    </definition>
  </paragraphs>
  <paragraphs>
    <title>Scalar multiplication</title>
    <definition>
      <title>Scalar multiplication</title>
      <statement>
        <p>
          Given any matrix <m>A=[a_{ij}]_{m\times n}</m> and any constant <m>c</m>,
          we define
          <me>
            cA=[ca_{ij}]
          </me>.
        </p>
        <p>
          We call <m>cA</m> a <term>scalar multiple</term> of <m>A</m>.
        </p>
      </statement>
    </definition>
  </paragraphs>
  <paragraphs>
  <title>Matrix multiplication</title>
  <paragraphs>
    <title>Warning:</title>
    <p>
      after all this,
      you might guess that we would define multiplication of two
      <m>m\times n</m> matrices <m>A</m> and <m>B</m> by taking the product of the corresponding entries.
      <em>NOT SO!</em>
    </p>
  </paragraphs>
  <definition>
    <statement>
      <p>
        Let <m>A=[a_{ij}]_{m\times r}</m> be an {<m>m\times r</m>} matrix,
        and <m>B=[b_{ij}]_{r\times n}</m> be an {<m>r\times n</m>} matrix.
      </p>
      <p>
        We define their <term>product</term>,
        <m>A\cdot B</m> to be the {<m>m\times n</m>} matrix <m>C=[c_{ij}]_{m\times n}</m>, where
        <me>
          c_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots a_{ir}b_{rj} =\sum_{\ell=1}^ra_{i\ell}b_{\ell j}
        </me>.
      </p>
    </statement>
  </definition>
  <p>
    Note the many peculiarities of this definition:
    <ol>
      <li>
        <p>
          In general <m>A_{{\color{red}m\times r}}</m>,
          <m>B_{\color{blue} r\times n}</m> and
          <m>C_{\color{green} m\times n}</m> all have different sizes!
        </p>
      </li>
      <li>
        <p>
          The rule for getting the entries of
          <m>A\cdot B</m> is nowhere near as simple as we may have hoped!
        </p>
      </li>
    </ol>
  </p>
  </paragraphs>
  <paragraphs>
    <title>Matrix multiplication</title>
    <p>
      For the product of <m>A</m> and <m>B</m> to be defined,
      we need the number of columns of <m>A</m> to be equal to the number of rows of <m>B</m>.
      That is, the
      <q>inside</q>
      dimensions in the product below must be equal.
      <me>
        A_{m\times\color{red} r}\cdot B_{{\color{red}{r}}\times n}=C_{m\times n}
      </me>
      <me>
        A_{{\color{blue}m}\times r}\cdot B_{r\times {\color{blue}n}}=C_{m\times n}
      </me>
    </p>
    <p>
      The
      <q>outside</q>
      dimensions tells us the dimension of the resulting matrix.
    </p>
    <p>
      All of this will make more sense once we begin thinking of matrices <m>A</m> as defining certain functions <m>T_A</m>.
      It turns out that the product of two matrices
      <m>A\cdot B</m> will represent the <em>composition</em>
      of their corresponding functions:
      i.e., <m>T_A\circ T_B</m>.
    </p>
    <p>
      The peculiar restriction on the dimensions of the matrices ensures that the two functions <m>T_A</m> and <m>T_B</m> can be composed:
      that is, that the range of <m>T_B</m> lies within the domain of <m>T_A</m>.
      More on this later!
    </p>
  </paragraphs>
  <paragraphs>
    <title>Alternative methods of multiplication</title>
    <p>
      In addition to the straightforward definition of matrix multiplication,
      we will make <em>heavy use</em>
      of a couple of alternative methods to computing products.
    </p>
    <p>
      To articulate these other methods,
      we need the following notion.
    </p>
    <definition>
      <title>Linear combination of matrices</title>
      <statement>
        <p>
          Let <m>A_1,A_2,\dots, A_r</m> be matrices of the same size,
          and let <m>c_1,c_2, \dots ,c_r</m> be scalars.
          The matrix
          <me>
            c_1A_1+c_2A_2\cdots +c_rA_r
          </me>
          is called a <term>linear combination</term> of the <m>A_i</m>,
          with <term>coefficients</term> <m>c_i</m>.
        </p>
      </statement>
    </definition>
  </paragraphs>
  <paragraphs>
    <title>Column method of $AB$</title>
    <p>
      Given a matrix <m>A_{m\times n}</m>,
      we will think of <m>A</m> as a sequence of <m>n</m> column vectors:
      <me>
        \begin{bmatrix}a_{11}\amp a_{12}\amp \cdots \amp a_{1n}\\ a_{21}\amp a_{22}\amp \cdots \amp a_{2n}\\ \vdots\amp \vdots \amp \cdots\amp \vdots \\ a_{m1}\amp a_{m2}\amp \cdots\amp a_{mn} \end{bmatrix} = \begin{bmatrix}\vert \amp \vert \amp  \amp  \vert\\ \bolda_1\amp \bolda_2\amp \cdots \amp \bolda_n\\ \vert\amp \vert \amp  \amp \vert \end{bmatrix}
      </me>
    </p>
    <p>
      Then for any column vector <m>\boldb=[b_{i}]</m> we have
      <me>
        A\boldb=A\cdot\begin{bmatrix}b_1\\b_2\\ \vdots \\b_n \end{bmatrix} = b_1\bolda_1+b_2\bolda_2+\cdots +b_n\bolda_n
      </me>.
    </p>
    <p>
      Next, we treat any <m>n\times r</m> matrix
      <m>B_{n\times r}</m> as a sequence of column vectors <m>B=\begin{bmatrix}\vert \amp \vert \amp  \amp \vert \\ \boldb_1\amp \boldb_2\amp \cdots\amp \boldb_r\\ \vert \amp \vert \amp  \amp \vert \end{bmatrix}</m>.
      Then we have
      <me>
        AB=A\begin{bmatrix}\vert \amp \vert \amp  \amp \vert \\ \boldb_1\amp \boldb_2\amp \cdots\amp \boldb_r\\ \vert \amp \vert \amp  \amp \vert \end{bmatrix} =\begin{bmatrix}\vert \amp \vert \amp  \amp \vert \\ A\boldb_1\amp A\boldb_2\amp \cdots\amp A\boldb_r\\ \vert \amp  \vert \amp  \amp  \vert \end{bmatrix}
      </me>.
    </p>
  </paragraphs>
  <paragraphs>
    <title>Row method of $AB$</title>
    <p>
      Given a matrix <m>B_{n\times r}</m>,
      we will think of <m>B</m> as a sequence of <m>m</m> row vectors:
      <me>
        \begin{bmatrix}b_{11}\amp b_{12}\amp \cdots \amp b_{1r}\\ \hline b_{21}\amp b_{22}\amp \cdots \amp b_{2r}\\ \hline \vdots\amp \vdots \amp \cdots\amp \vdots \\ \hline b_{n1}\amp b_{n2}\amp \cdots\amp b_{nr} \end{bmatrix} = \begin{bmatrix}-\boldb_1-\\ -\boldb_2- \\ \vdots \\ -\boldb_n- \end{bmatrix}
      </me>
    </p>
    <p>
      Then for any row vector <m>\bolda=\begin{bmatrix}a_1\amp a_2\amp \cdots \amp a_n \end{bmatrix}</m> we have
      <me>
        \bolda B=\begin{bmatrix}a_1\amp a_2\amp \cdots \amp a_n \end{bmatrix} B= a_1\boldb_1+a_2\boldb_2+\cdots +a_n\boldb_n
      </me>.
    </p>
    <p>
      Next, we treat any <m>m\times n</m> matrix
      <m>A_{m\times n}</m> as a sequence of row vectors and compute
      <me>
        AB=\begin{bmatrix}-\bolda_1- \\ -\bolda_2- \\ \vdots \\ -\bolda_m- \end{bmatrix} B = \begin{bmatrix}-\bolda_1B- \\ -\bolda_2B- \\ \vdots \\ -\bolda_mB- \end{bmatrix}
      </me>
    </p>
  </paragraphs>
  <paragraphs>
  <title>Transpose of a matrix</title>
  <definition>
    <statement>
      <p>
        Given an <m>m\times n</m> matrix
        <m>A=[a_{ij}]</m> its transpose <m>A^T</m> is the matrix whose <m>ij</m>-entry is the <m>ji</m>-th entry of <m>A</m>.
        Using notation we have <m>A^T=[b_{ij}]_{n\times m}</m>,
        where <m>b_{ij}=a_{ji}</m>.
        Note in particular that <m>A^T</m> is <m>n\times m</m>.
      </p>
    </statement>
  </definition>
  <paragraphs>
    <title>Examples:</title>
    <p>
      let <m>A=\begin{bmatrix}1\amp 2\amp 3\\4\amp 5\amp 6 \end{bmatrix}</m>;
      then <m>A^T=\begin{bmatrix}1\amp 4\\2\amp 5\\3\amp 6 \end{bmatrix}</m>.
      Let <m>B=\begin{bmatrix}1\\0\\3 \end{bmatrix}</m>,
      then <m>B^T=\begin{bmatrix}1\amp 0\amp 3 \end{bmatrix}</m>.
    </p>
  </paragraphs>
  <paragraphs>
    <title>Comment:</title>
    <p>
      there are a couple of equivalent ways of describing <m>A^T</m> that may be more helpful depending on the situation:
    </p>
  </paragraphs>
  <ul>
    <li>
      <p>
        <m>A^T</m> is the matrix whose columns are the rows of <m>A</m>.
      </p>
    </li>
    <li>
      <p>
        <m>A^T</m> is the matrix whose rows are the columns of <m>A</m>.
      </p>
    </li>
  </ul>
  </paragraphs>
</section>
