<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="s_basis_dimension">
  <title>Bases and dimension</title>
<introduction>
  <p>
    Now that we have the notions of span and linear independence in place, we simply combine them to define a <em>basis</em> of a vector space. In the spirit of <xref ref="s_span_independence"/>, a basis of a vector space <m>V</m> should be understood as a <em>minimal</em> spanning set.
  </p>
  <p>
   This section includes many theoretical results. There are two in particular that are worth highlighting, especially in regard to computational techniques for abstract vector spaces:
   <ol>
     <li>
       <p>
         If <m>B</m> is a basis of <m>V</m> containing exactly <m>n</m> elements, then any other basis <m>B'</m> also contains exactly <m>n</m> elements. (<xref ref="th_basis_dimension"/>)
       </p>
     </li>
     <li>
       <p>
         If <m>B</m> is a basis for <m>V</m>, then every element of <m>V</m> can be written as a linear combination of elements of <m>B</m> in a <em>unique way</em>. (<xref ref="th_basis_equivalence"/>)
       </p>
     </li>

   </ol>
   The first result allows us to define the <em>dimension</em> of a vector space as the number of elements in any given basis. The second result allows us to take any <m>n</m>-dimensional vector space <m>V</m> with chosen basis <m>B=\{\boldv_1, \boldv_2, \dots, \boldv_n\}</m> and effectively identify vectors <m>\boldv\in V</m> with the sequence <m>(c_1,c_2,\dots, c_n)\in \R^n</m>, where
   <me>
     \boldv=c_1\boldv_1+c_2\boldv_2+\cdots c_n\boldv_n
   </me>.
   This observation has the following consequence: given any <m>n</m>-dimensional vector space <m>V</m>, no matter how exotic, once we choose a basis <m>B</m> of <m>V</m>, we can reduce any and all linear algebraic questions or computations about <m>V</m> to a corresponding question in <m>\R^n</m>. We will elaborate this idea further in <xref ref="s_coordinatevectors"/>.
  </p>
</introduction>

  <subsection xml:id="ss_bases">
    <title>Bases of vector spaces</title>
    <definition xml:id="d_basis">
      <title>Basis</title>
      <idx><h>basis</h><h>of a vector space</h></idx>
      <statement>
        <p>
          A subset <m>B</m> of a vector space <m>V</m> is called a <term>basis</term> if
          <ol label="i">
            <li>
              <p>
                <m>B</m> spans <m>V</m>, and
              </p>
            </li>
            <li>
              <p>
                <m>B</m> is linearly independent.
              </p>
            </li>
          </ol>
          If the basis <m>B</m> comes equipped with an ordering (<ie />, <m>B</m> is an ordered set), then we call <m>B</m> and <term>ordered basis</term>
        </p>
      </statement>
    </definition>
        <remark xml:id="rm_standard_bases">
        <title>Some standard bases</title>
      <statement>
        <p>
          The examples of standard spanning sets in <xref ref="rm_spanning_sets"/> are easily seen to be linearly independent, and hence are in fact bases. We list them again here, using the same notation, and refer to these as <em>standard bases</em> for the given spaces.
        </p>
        <ul>
        <li>
          <title>Zero space</title>
          <p>
          Let <m>V=\{\boldzero\}</m>. The empty <m>B=\emptyset=\{ \}</m> is a basis for <m>V</m>. Note that <m>B=\emptyset</m> spans <m>V</m> by definition (<xref ref="d_span"/>), and it satisfies the defining implication of linear independence (<xref ref="d_linear_independence"/>) trivially.
          </p>
        </li>
        <li>
          <title>Tuples</title>
          <p> Let <m>V=\R^n</m>.
          The set <m>B=\{\bolde_1, \bolde_2,\dots, \bolde_n\}</m> is the standard basis of <m>\R^n</m>.
          </p>
        </li>
        <li>
          <title>Matrices</title>
          <p>
          Let <m>V=M_{mn}</m>. The set <m>B=\{E_{ij}\colon 1\leq i\leq m, 1\leq j\leq n\}</m> is the standard basis of <m>M_{mn}</m>.
          </p>
        </li>
        <li>
          <title>Polynomials of bounded degree</title>
          <p>
          Let <m>V=P_n</m>. The set <m>B=\{x^n, x^{n-1}, \dots, x, 1\}</m> is the standard basis of <m>P_n</m>.
          </p>
        </li>
        <li>
          <title>Polynomials</title>
          <p>
          Let <m>V=P</m>, the space of all polynomials. The set
          <me>B=\{1, x, x^2, \dots\}=\{x^i\colon i\geq 0\} </me>
          is the standard basis of <m>P</m>.
          </p>
        </li>
      </ul>
      </statement>
    </remark>
<p>
  Just as with spanning sets, bases are not in general unique: in fact, for any nonzero vector space there are infinitely many different bases.
</p>
<example>
  <title>Some nonstandard bases</title>
  <statement>
    <p>
      For each <m>V</m> and <m>B</m> below, verify that <m>B</m> is a basis of <m>V</m>.
      <ol>
        <li>
          <p>
            <m>V=\R^2</m>,
            <m>B=\{(1,1), (1,-1)\}</m>.
          </p>
        </li>
        <li>
          <p>
            <m>V=P_2</m>, <m>B=\{x^2+x+1, x^2-x, x^2+1\}</m>.
          </p>
        </li>
        <li>
          <p>
            <m>V=M_{22}</m>,
            <me>
              B=\left\{ \begin{bmatrix}3\amp 6\\ 3\amp -6 \end{bmatrix} , \begin{bmatrix}0\amp -1\\ -1\amp 0 \end{bmatrix} , \begin{bmatrix}0\amp -8\\ -12\amp -4 \end{bmatrix} , \begin{bmatrix}1\amp 0\\ -1\amp 2 \end{bmatrix} \right\}
            </me>.
          </p>
        </li>
      </ol>
    </p>
  </statement>
  <solution>
    <p>
    Each verification amounts to showing, using the techniques from <xref ref="s_span_independence"/>, that the given <m>B</m> spans the given <m>V</m> and is linearly independent. We illustrate with (1) and (2), leaving (3) to the reader.
    </p>
    <ol>
      <li>
        <p>
          Since neither element of <m>B=\{(1,1), (1,-1)\}</m> is a scalar multiple of the other, the set is linearly independent. To see that <m>B</m> spans <m>\R^2</m> we show that for any <m>(c,d)\in \R^2</m> we have
          <me>
            a(1,1)+b(1,-1)=(c,d)
          </me>
          for some <m>a,b\in \R</m>. Indeed we may take <m>a=\frac{1}{2}(c+d)</m> and <m>b=\frac{1}{2}(c-d)</m>. (These formulas were obtained by solving the corresponding system of two equations in the unknowns <m>a</m> and <m>b</m>.)
        </p>
      </li>
      <li>
        <p>
          To show <m>B</m> spans <m>P_2</m> we must show that for any <m>dx^2+ex+f\in P_2</m> we can find <m>a,b,c\in\R</m> such that
          <me>
            a(x^2+x+1)+b(x^2-x)+c(x^2-1)=dx^2+ex+f
          </me>,
          or
          <me>
            (a+b+c)x^2+(a-b)x+(a-1)=dx^2+ex+f
          </me>.
          Equating coefficients yields the system of equations
          <me>
            \begin{linsys}{3}
              a\amp +\amp b\amp +\amp c\amp = d\\
              a\amp -\amp b\amp \amp \amp =e\\
              a\amp  \amp  \amp -\amp c\amp =f
            \end{linsys}
          </me>,
          which corresponds to the matrix equation
          <me>
            \underset{A}{\begin{amatrix}[rrr]1\amp 1\amp 1\\ 1\amp -1\amp 0\\ 1\amp 0\amp -1\end{amatrix}}\underset{\boldx}{\begin{bmatrix} a\\ b\\ c\end{bmatrix}}=\underset{\boldy}{\begin{bmatrix} d\\ e\\ f\end{bmatrix}}
          </me>.
          An easy computation shows <m>\det A=3</m>, and thus that <m>A</m> is invertible. We conclude that the system can be solved for <m>(a,b,c)</m> (set <m>\boldx=A^{-1}\boldy</m>), and thus that <m>B</m> spans <m>P_2</m>.
        </p>
        <p>
          Our work above now can be used to also show that <m>B</m> is linearly independent. Replacing the arbitrary polynomial <m>dx^2+ex+f</m> with the zero polynomial <m>0x^2+0x+0</m>, we see that a linear combination
          <me>
            a(x^2+x+1)+b(x^2-x)+c(x^2-1)=\boldzero
          </me>
          corresponds to a solution <m>\boldx=(a,b,c)</m> to the matrix equation <m>A\boldx=\boldzero</m>. Since <m>A</m> is invertible, we conclude that <m>\boldx=\boldzero</m> (<xref ref="th_invertibility_expanded"/>), and thus that <m>a=b=c=0</m>. This shows <m>B</m> is linearly independent.
        </p>
      </li>
    </ol>
  </solution>
</example>
<p>
 Not every vector space has a finite basis, as we show in the next example.
</p>
<example>
  <title><m>P</m> has no finite basis</title>

  <statement>
    <p>
      Prove that <m>P</m>, the space of all real polynomials, does not have a finite basis.
    </p>
  </statement>
  <solution>
    <p>
      We show that no finite set of polynomials can span all of <m>P</m>; it follows that <m>P</m> does not have a finite basis.
    </p>
    <p>
    Indeed let <m>S=\{p_1, p_2, \dots, p_r\}</m> be a finite set of polynomials, and let <m>n</m> be the maximal degree of all the polynomials <m>p_i\in S</m>. Then <m>p_i\in P_n</m> for all <m>i</m>, in which case <m>\Span S\subseteq P_n</m>: <ie />, <m>\Span S</m> is a subspace of the space of polynomials of degree at most <m>n</m>. Since <m>P_n\subsetneq P</m>, we conclude that <m>\Span S\ne P</m>, as claimed.
    </p>
  </solution>
</example>
    <remark xml:id="rm_dimension_functionspaces">
  <statement>
    <p>
      By <xref ref="th_dimension_compendium"/> and its corollaries, we know that if <m>V</m> has a finite basis, then and subspace of <m>V</m> also has a finite basis. Let <m>X\subseteq \R</m> be an interval. Since
      <me>
        P\subseteq C^\infty(X)\subseteq C^n(X)\subseteq C(X)\subseteq F(X,\R)
      </me>
      is a chain of subspaces, and since <m>P</m> does not have a finite basis, we conclude that none of these other function spaces has a finite basis.
    </p>
  </statement>
</remark>
<example>
  <title>Basis for <m>\R_{>0}</m></title>
  <statement>
    <p>
    Let <m>V=\R_{>0}</m>, and let <m>S=\{\boldv\}</m>, where <m>\boldv=a</m> is any positive real number. Prove: <m>S</m> is a basis if and only if <m>a\ne 1</m>.
    </p>
  </statement>
  <solution>
    <case>
     <title><m>(a=1\implies S \text{ not a basis})</m></title>
    <p>
    Suppose <m>a=1</m>. Since <m>1=\boldzero\in V</m>, we have <m>S=\{\boldzero\}</m>. Any set containing the zero vector is linearly dependent (<xref ref="rm_linear_independence"/>). Thus <m>S</m> is not a basis.
    </p>
    </case>
    <case>
     <title><m>(a\ne 1 \implies S \text{ is a basis})</m></title>
    <p>
    Since <m>S=\{\boldv\}</m> consists of one nonzero element, it is linearly independent (<xref ref="rm_linear_independence"/>). It remains only to show that <m>S</m> spans <m>\R_{>0}</m>, which amounts to showing that every <m>b\in \R_{>0}</m> is a scalar multiple of <m>\boldv=a</m>. Since by definition scalar multiplication in <m>\R_{>0}</m> is defined as <m>c\boldv=a^c</m>, this is equivalent to showing that every <m>b\in \R_{>0}</m> can be written in the form <m>b=a^c</m>. This fact is a familiar result from calculus, where you learn that the range (or image) of any exponential function <m>f(x)=a^x</m> is the set of all positive real numbers.
    </p>
    </case>
  </solution>
</example>
<p>
  Proceeding directly from the definition, to show a set <m>B</m> is a basis of <m>V</m> we have to do two steps: (i) show <m>\Span B= V</m>; (ii) show that <m>B</m> is linearly independent. The following theorem offers gives rise to a one-step technique for proving <m>B</m> is a basis: show that every element of <m>V</m> can be written as a linear combination of elements of <m>B</m> in a <em>unique way</em>.
</p>
<theorem xml:id="th_basis_equivalence">
  <title>Basis equivalence</title>
  <statement>
    <p>
    Let <m>B</m> be a subset of the vector space <m>V</m>. The following statements are equivalent:
    </p>
    <ol>
      <li>
        <p>
          The set <m>B</m> is a basis of <m>V</m>
        </p>
      </li>
      <li>
        <p>
          Every element <m>\boldv\in V</m> can be written as a linear combination of elements of <m>B</m>, and furthermore this linear combination is unique: <ie /> if we have
          <me>
            \boldv=c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=d_1\boldv_1+d_2\boldv_2+\cdots +d_s\boldv_r
          </me>,
          where <m>\boldv_i\in B</m> and <m>\boldv_i\ne \boldv_j</m> for all <m>1\leq i, j\leq r</m>, then <m>c_i=d_i</m> for all <m>1\leq i\leq r</m>.
        </p>
      </li>
    </ol>
  </statement>
  <proof>
      <case>
       <title>Implication: <m>(1)\implies (2)</m></title>
      <p>
      Suppose <m>B</m> is a basis. By definition, <m>B</m> spans <m>V</m>, and so every element of <m>V</m> can be written as a linear combination of elements of <m>B</m>. It remains to show that this linear combination is unique in the sense described. This follows from the fact that <m>B</m> is linearly independent. Indeed, we have
      <md>
        <mrow> c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=d_1\boldv_1+d_2\boldv_2+\cdots +d_r\boldv_r \amp \implies
        c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r-(d_1\boldv_1+d_2\boldv_2+\cdots +d_r\boldv_r)=\boldzero </mrow>
        <mrow> \amp\implies (c_1-d_1)\boldv_1+(c_2-d_2)\boldv_2+\cdots +(c_r-d_r)\boldv_r=\boldzero </mrow>
        <mrow>  \amp \implies c_i-d_i=0 \text{ for all } i \amp (B \text{ lin. independent}) </mrow>
        <mrow>  \amp \implies c_i=d_i \text{ for all } i </mrow>
      </md>.
      </p>
      </case>
      <case>
       <title>Implication: <m>(2)\implies (1)</m></title>
      <p>
      If <m>B</m> satisfies (2), then clearly it spans <m>V</m>. The uniqueness of linear combinations of elements of <m>B</m> now easily implies <m>B</m> is linearly independent:
      <md>
        <mrow>c_1\boldv_1+c_2\boldv_2+\cdots c_r\boldv_r=\boldzero \amp \implies
         c_1\boldv_1+c_2\boldv_2+\cdots c_r\boldv_r=0\boldv_1+0\boldv_2+\cdots 0\boldv_r</mrow>
         <mrow>  \amp \implies c_1=0, c_2=0, \dots, c_r=0 \amp \text{(by uniqueness condition)}</mrow>
      </md>.
      </p>
      </case>
  </proof>
</theorem>
<p>
  <xref ref="th_basis_equivalence"/> yields the following one-step technique for proving a set is a basis.
</p>
<algorithm xml:id="proc_basis_onestep">
  <title>One-step technique for bases</title>
  <statement>
    <p>
      Let <m>V</m> be a vector space. To prove a subset <m>B\subseteq V</m> is a basis it suffices to show that every <m>\boldv\in V</m> can be written as a linear combination of elements of <m>B</m> in a unique way, as specified in <xref ref="th_basis_equivalence"/>.
    </p>
  </statement>
</algorithm>
<example xml:id="eg_basis_onestep">
  <title>One-step technique for bases</title>
  <statement>
    <p>
    Use the one-step technique to verify that
          <me>B=\{p(x)=2x+1, x+1\}</me>
    is a basis of <m>P_1</m>
    </p>
  </statement>
  <solution>
    <p>
    Take an arbitrary element <m>ax+b\in P_1</m> and consider the polynomial equation
            <me>
              c_1p(x)+c_2q(x)=ax+b
            </me>
            The usual remark about polynomial equality implies that this is equivalent to the matrix equation
            <me>
            \begin{bmatrix}
            2\amp 1\\ 1\amp 1
            \end{bmatrix}
            \begin{bmatrix}
              c_1 \\ c_2
            \end{bmatrix}
            =
            \begin{bmatrix}
              a\\ b
            \end{bmatrix}
            =\boldy
            </me>.
            The matrix on the left is invertible, allowing us to solve:
            <me>
            \begin{bmatrix}
              c_1 \\ c_2
            \end{bmatrix}
            =\begin{bmatrix}
            1\amp -1\\ -1\amp 2
            \end{bmatrix}
            \begin{bmatrix}
              a\\ b
            \end{bmatrix}
            =\begin{bmatrix}
              a-b\\ -a+2b
            \end{bmatrix}
            </me>.
            We conclude that any <m>ax+b\in P_1</m> can be written as <m>c_1p+c_2q</m> in a unique way: namely, with <m>c_1=a-b</m> and <m>c_2=-a+2b</m>. Thus <m>S</m> is a basis.
          </p>
  </solution>
</example>
</subsection>
<subsection xml:id="ss_dimension">
  <title>Dimension of a a vector space</title>
  <p>
    The next few results are all in the service of establishing a notion of <em>dimension</em> for a vector space <m>V</m>, which we define to be the number of elements in a basis for <m>V</m>. For this to be a well-defined quantity, we need to show that any two bases for a vector space have the same number of elements.
  </p>
  <definition xml:id="d_cardinality">
    <title>Cardinality of a set</title>
    <idx><h>cardinality</h><h>of a set</h></idx>
    <notation>
      <usage><m>\val{X}</m></usage>
      <description>the cardinality of the set <m>X</m></description>
    </notation>
    <statement>
      <p>
      Let <m>X</m> be a set. The <term>cardinality of <m>X</m></term>, denoted <m>\val{X}</m> is defined as follows:
      <ul>
        <li>
          <p>
            If <m>X</m> is finite, then its cardinality is the number <m>n</m> of distinct elements it contains, written <m>\val{X}=n</m>.
          </p>
        </li>
        <li>
          <p>
            If <m>X</m> is infinite, then we say it has <term>infinite cardinality</term>, and write <m>\val{X}=\infty</m>.
          </p>
        </li>
      </ul>
      </p>
    </statement>
  </definition>
  The following theorem is the crucial result needed to show that any two finite bases of a vector space have the same cardinality.
  <theorem xml:id="th_basis_span_bounds">
    <statement>
      <p>
        Suppose <m>S</m> is a finite spanning set for the vector space <m>V</m> and let <m>\val{S}=n</m>. If <m>S'</m> is a finite set with <m>\val{S'}=r>n</m>, then <m>S'</m> is linearly dependent.
      </p>
    </statement>
    <proof>
      <p>
        Let <m>S=\{\boldv_1, \boldv_2, \dots, \boldv_n\}</m>, and let <m>S'=\{\boldw_1, \boldw_2, \dots, \boldw_r\}</m>. Since <m>S</m> spans <m>V</m>, each element of <m>S'</m> is a linear combination of elements of <m>S</m>: <ie />, we have
        <men xml:id="eq_basis_bound">
          \boldw_j=a_{1j}\boldv_1+a_{2j}\boldv_2+\cdots a_{nj}\boldv_n=\sum_{i=1}^n\boldv_{ij}
        </men>
        for all <m>1\leq j\leq r</m>. Now consider the following chain of equivalences:
        <md>
          <mrow>c_1\boldw_1+c_2\boldw_2+\cdots c_r\boldw_r=\boldzero \amp \iff c_1(\sum_{i=1}^n\boldv_{i1})+c_2(\sum_{i=1}^n\boldv_{i2})+\cdots +c_r\sum_{i=1}^n\boldv_{in}=\boldzero\amp (<xref ref="eq_basis_bound"/>) </mrow>
          <mrow>  \amp \iff \sum_{j=1}^rc_j\sum_{i=1}^na_{ij}\boldv_i=\boldzero</mrow>
          <mrow> \amp\iff \sum_{i=1}^n(\sum_{j=1}^ra_{ij}c_j)\boldv_i=\boldzero  </mrow>
          <mrow>  \amp \iff (\sum_{j=1}^ra_{1j}c_j)\boldv_1+(\sum_{j=1}^ra_{2j}c_j)\boldv_2+\cdots (\sum_{j=1}^ra_{nj}c_j)\boldv_n=\boldzero </mrow>
        </md>.
        From the last vector equation, we see that if we can find a nonzero sequence <m>(c_1,c_2,\dots, c_r)</m> satisfying
        <me>
          \sum_{j=1}^ra_{ij}c_j=0
        </me>
        for all <m>1\leq i\leq n</m>, then there is a nontrivial combination of the <m>\boldw_i</m> equal to the zero vector, and hence that <m>S'</m> is linearly dependent. Such a sequence <m>(c_1,c_2,\dots, c_n)</m> corresponds to a solution to the homogeneous linear with augmented matrix
        <me>
          \begin{amatrix}[r|r]
          A\amp \boldzero
          \end{amatrix}
        </me>,
        where <m>A=[a_{ij}]_{n\times r}</m>. Since this is a homogeneous system of <m>n</m> equations in <m>r</m> unknowns, and since <m>r>n</m>, there are in fact infinitely many solutions. (The system has at most <m>n</m> leading ones, and so there must be a free variable since one of the <m>r</m> columns in the equivalent row echelon matrix must fail to contain a leading one.) In particular there is a nonzero solution <m>(c_1,c_2,\dots, c_n)\ne \boldzero</m>, and we conclude that <m>S'</m> is linearly dependent.
      </p>
    </proof>
  </theorem>
  The next theorem not only ensures that our definition of dimension (<xref text="global" ref="d_dimension"/>) is well-defined, it also characterizes dimension as the minimal cardinality of a spanning set, and the maximal cardinality of a linearly independent set.
  <theorem xml:id="th_basis_dimension">
    <title>Basis bounds</title>
    <statement>
      <p>
      Let <m>B</m> be a basis of the vector space <m>V</m>, and suppose <m>\val{B}=n</m>
      </p>
      <ol>
        <li>
          <p>
            If <m>S</m> spans <m>V</m>, then <m>\val{S}\geq n</m>.
          </p>
        </li>
        <li>
          <p>
            If <m>S</m> is linearly independent, then <m>\val{S}\leq n</m>.
          </p>
        </li>
        <li>
          <p>
            If <m>B'</m> is a basis for <m>V</m>, then <m>\val{B'}=n</m>.
          </p>
        </li>
      </ol>
    </statement>
    <proof>
      <p>
        <ol>
          <li>
            <p>
              Suppose by contradiction that <m>\Span S=V</m> and <m>\val{S} &lt; n</m>. Then <xref ref="th_basis_span_bounds"/> would imply <m>B</m> is linearly dependent. Since this is a contradiction, we conclude that <m>\val{S}\geq n</m>.
            </p>
          </li>
          <li>
            <p>
              This also follows from <xref ref="th_basis_span_bounds"/>: since <m>B</m> is a spanning set of <m>V</m> any set containing more than <m>n=\val{B}</m> elements must be linearly dependent.
            </p>
          </li>
          <li>
            <p>
              This follows from (1) and (2): if <m>B'</m> is a basis, then since <m>B'</m> spans, we have <m>\val{B'}\geq n</m> (1); and since <m>B</m> is linearly independent we have <m>\val{B'}\leq n</m> (2). We conclude that <m>\val{B'}=n</m>.
            </p>
          </li>
        </ol>
      </p>
    </proof>
  </theorem>
  <definition xml:id="d_dimension">
    <title>Dimension of a vector space</title>
    <idx><h>dimension</h><h>of a vector space</h></idx>
    <notation>
      <usage><m>\dim V</m></usage>
      <description>dimension of <m>V</m></description>
    </notation>
    <statement>
      <p>
        Let <m>V</m> be a vector space. The <term>dimension of <m>V</m></term>, denoted <m>\dim V</m>, is defined as follows:
        <ul>
          <li>
            <p>
            If <m>V</m> has a finite basis <m>B</m>, then the dimension of <m>V</m> is the number of elements of <m>B</m>: <ie />, <m>\dim V=\val{B}</m>.
            </p>
          </li>
          <li>
            <p>
              If <m>V</m> does not have a finite basis, then we say <m>V</m> is <term>infinite dimensional</term>, and write <m>\dim V=\infty</m>.
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </definition>
      <remark xml:id="rm_basis_existence">
    <statement>
      <p>
      Wouldn't it have been more natural to simply say <m>V</m> is infinite dimensional if it has an infinite basis? As it turns out this is indeed equivalent to not having a finite basis, but to prove this we need to establish the general fact that we can always find a basis for a given vector space <m>V</m>. As intuitive as that claim may sound (<ie />, that bases always exist), its proof requires some set theory methods that are not covered in this text. As such we will not include it in our treatment of dimension, and so will have to make do with our slightly awkward definition of infinite-dimensional vector spaces.
      </p>
    </statement>
  </remark>
    <remark xml:id="rm_computing_dimension">
  <title>Computing dimension</title>
  <statement>
    <p>
      By definition, to show a vector space <m>V</m> has dimension <m>n</m>, we must exhibit a basis <m>B</m> with <m>\val{B}=n</m>. Similarly to show <m>V</m> is infinite dimensional, we must show that it does not have a finite basis: equivalently, if you believe <xref ref="rm_basis_existence"/>, we must exhibit an infinite basis of <m>V</m>.
    </p>
    <p>
      Consider our list of familiar vector spaces, for example. Since each vector spaces on this list comes equipped with a standard basis, we compute its dimension simply by counting the elements in the given standard basis.  For each <m>V</m> below we provide its standard basis <m>B</m> and compute <m>\dim V=\val{B}</m>.
    </p>
    <ul>
    <li>
      <title>Zero space</title>
      <p>
      <m>V=\{\boldzero\}</m>, <m>B=\emptyset=\{ \}</m>, <m>\dim V=0</m>
      </p>
    </li>
    <li>
      <title>Tuples</title>
      <p>
      <m>V=\R^n</m>, <m>B=\{\bolde_1, \bolde_2,\dots, \bolde_n\}</m>, <m>\dim V=\val{B}=n</m>
      </p>
    </li>
    <li>
      <title>Matrices</title>
      <p>
      <m>V=M_{mn}</m>, <m>B=\{E_{ij}\colon 1\leq i\leq m, 1\leq j\leq n\}</m>, <m>\dim V=\val{B}=m\, n</m>
      </p>
    </li>
    <li>
      <title>Polynomials of bounded degree</title>
      <p>
      <m>V=P_n</m>, <m>B=\{x^n, x^{n-1}, \dots, x, 1\}</m>, <m>\dim V=\val{B}=n+1</m>
      </p>
    </li>
    <li>
      <title>Polynomials</title>
      <p>
      <m>V=P</m>, <m>B=\{1,x, x^2, \dots\}</m>, <m>\dim V=\val{B}=\infty</m>
      </p>
    </li>
    </ul>
  </statement>
</remark>
The <q>contracting and expanding</q> theorem below is very useful theoretical consequence of <xref ref="th_basis_dimension"/>. It allows us to construct a customized basis from a given set <m>S</m>. This method is used prominently in the proof of the <xref ref="th_rank-nullity" text="custom">rank-nullity theorem </xref>.
<theorem xml:id="th_basis_contract_expand">
  <title>Contracting and expanding to bases</title>
  <statement>
    <p>
    Let <m>V</m> be a vector space of dimension <m>n</m>, and let <m>S\subseteq V</m> be a finite subset.
    </p>
    <ol>
      <li>
        <title>Contract to basis</title>
        <p>
          If <m>S</m> spans <m>V</m>, then there is a subset of <m>S</m> that is a basis of <m>V</m>: <ie />, we can <em>contract</em> a spanning set to a basis.
        </p>
      </li>
      <li>
      <title>Extend to basis</title>
        <p>
          If <m>S</m> is linearly independent, then <m>S</m> is contained in a basis of <m>V</m>: <ie />, we can <em>extend</em> a linearly independent set to a basis.
        </p>
      </li>
    </ol>
  </statement>
  <proof>
    <p> Let <m>S=\{\boldv_1, \boldv_2, \dots , \boldv_r\}</m>.
      <ol>
        <li>
          <p>
          Assume <m>\Span S=V</m>. Let <m>S'</m> be a subset of <m>S</m> of <em>minimal cardinality</em> such that <m>\Span S'</m> is still equal to <m>V</m>. Such a set is guaranteed to exist: since <m>S</m> is finite, it has a finite number of subsets; of these subsets some will span, others will not; of the subsets that do span, there will be one (or more) that has the least number of elements.
          </p>
          <p>
            We claim that such a spanning subset <m>S'</m> of minimal cardinality is linearly independent, and hence is a basis for <m>V</m>, as desired. We give a proof by contradiction. Suppose <m>S'</m> is linearly dependent. Then some element of <m>S'</m>, call it <m>\boldv_0</m>, can be expressed as a linear combination of the other elements (<xref ref="rm_linear_independence"/>). Then in terms of span, the element <m>\boldv_0</m> is <q>redundant</q>. In other words, if we let <m>S''=S'-\{\boldv_0\}</m>, the set obtained by <q>throwing out</q> <m>\boldv_0</m>, then we have <m>\Span S''=\Span S'=V</m>. Since <m>\val{S''} &lt; \val{S}</m>, this contradicts our choice of <m>S'</m> as a spanning set of minimal cardinality. We conclude that <m>S'</m> is linearly independent, completing the proof.
          </p>
        </li>
        <li>
          <p>
            Assume <m>S</m> is linearly independent. The procedure below constructs a finite chain of sets
            <me>
              S=S_0\subseteq S_1\dots \subseteq S_k
            </me>
            that ends with a basis <m>B=S_k</m>.
            <ul>
              <li>
                <title>Initialization</title>
                <p>
                Let <m>S=S_0</m>
                </p>
              </li>
              <li>
              <title>Expansion loop</title>
              <p>
              If <m>\Span S_i=V</m>, return <m>B=S_i</m>. Otherwise set <m>S_{i+1}=S_i\cup \{\boldv\}</m>, where <m>\boldv</m> is any element of <m>V</m> that is not contained in <m>\Span S_i</m> and repeat.
              </p>
            </li>
            </ul>
            Some observations:
            <ol label="i">
              <li>
                <p>
                Each <m>S_i</m> is linearly independent. This can be shown by induction, the crucial point being that if <m>S_i</m> is linearly independent, and if <m>\boldv\notin \Span S_i</m>, then <m>S_{i+1}=S_i\cup \{\boldv_0\}</m> is linearly independent. The proof is left as an exercise.
                </p>
              </li>
              <li>
                <p>
                  The procedure must halt. Why? Since <m>\dim V=n</m>, and since each <m>S_i</m> is linearly independent, we must have <m>\val{S_i}\leq n</m> for all <m>i</m> by <xref ref="th_basis_dimension"/>. Since <m>\val{S_i}&lt; \val{S_{i+1}}</m> and <m>\val{S_{i}}\leq n</m>, the procedure must halt in at most <m>n</m> steps.
                </p>
              </li>
            </ol>
            From (ii) we may assume the procedure halts at <m>S_k</m> for some <m>k\geq 0</m>. From (i) we know that <m>S_k</m> is linearly independent. Furthermore, since the procedure halts at <m>S_k</m>, we know that <m>\Span S_k=V</m>. It follows that <m>B=S_k</m> is a basis containing <m>S</m>, as desired.
          </p>
        </li>
      </ol>
    </p>
  </proof>
</theorem>
The following corollary follows from <xref ref="th_basis_dimension"/> and <xref ref="th_basis_contract_expand"/>. We call it a <q>street smarts</q> result as the first two statements give us a quick and dirty way of dashing a set's hopes of being a basis. The third statement asserts that when a finite set's cardinality matches the dimension of a space, then to prove it is a basis it suffices to prove either one of the two defining properties of <xref ref="d_basis"/>.
<corollary xml:id="cor_street_smarts">
  <title>Street smarts</title>
  <statement>
    <p>
    Let <m>V</m> be a vector space of dimension <m>n</m>, and let <m>S\subseteq V</m> be a subset.
    </p>
    <ol>
      <li>
        <p>
          If <m>\val{S} &lt; n</m>, then <m>S</m> does not span <m>V</m>.
        </p>
      </li>
      <li>
        <p>
          If <m>\val{S}>n</m>, then <m>S</m> is linearly dependent.
        </p>
      </li>
      <li>
        <p>
          If <m>\val{S}=n</m>, then the following are equivalent:
          <ol label="i">
            <li>
              <p>
                The set <m>S</m> is a basis.
              </p>
            </li>
            <li>
              <p>
                The set <m>S</m> spans <m>V</m>.
              </p>
            </li>
            <li>
              <p>
                The set <m>S</m> is linearly independent.
              </p>
            </li>
          </ol>
        </p>
      </li>
    </ol>
  </statement>
  <proof>
    <p>
      Statements (1) and (2) follow directly from <xref ref="th_basis_dimension"/>. Statement (3) is an easy consequence of <xref ref="th_basis_contract_expand"/>. For example, if <m>S</m> spans <m>V</m>, then there is a subset <m>S'</m> of <m>S</m> that is a basis of <m>V</m>; since all bases of <m>V</m> have <m>n</m> elements, and since <m>\val{S}=n</m>, we must have <m>S'=S</m>; thus <m>S</m> is a basis. The proof for a linear independent set <m>S</m> is similar, and is left to the reader.
    </p>
  </proof>

</corollary>
<p>
  We are often in a situation where we wish to show a given subspace of a vector space is in fact the entire space. For example, when deciding whether a set <m>S</m> spans a vector space <m>V</m>, we are asking whether <m>W=\Span S</m> is all of <m>V</m>. As another example, given a linear transformation <m>T\colon V\rightarrow W</m>, one of the first things we wish to determine is whether the subspace <m>\im T</m> is in fact all of <m>W</m>. As the next result illustrates, dimension is a very useful tool in this regard.
</p>
<corollary xml:id="cor_dimension_subspace">
  <title>Dimension of subspaces</title>
  <statement>
    <p>
    Let  <m>V</m> be a vector space.
    </p>
    <ol>
      <li>
        <p>
          If <m>W\subseteq V</m> is a subspace, then <m>\dim W\leq \dim V</m>.
        </p>
      </li>
      <li>
        <p>
          If <m>W\subseteq V</m> is a subspace, then <m>\dim W=\dim V</m> if and only if <m>W=V</m>.
        </p>
      </li>
    </ol>
  </statement>
  <proof>
    <p>
      <ol>
        <li>
          <p>
            Firstly, if <m>\dim V=\infty</m>, then clearly <m>\dim W\leq \dim V</m> for any subspace <m>W\subseteq V</m>.
          </p>
          <p>
            Now assume <m>\dim V=n</m>. Apply the <q>extending to a basis</q> procedure described in the proof of <xref ref="th_basis_contract_expand"/> to the emptyset <m>S=\{\}</m>, which is lienarly independent, considered as a subset of <m>W</m>: <ie />, at each stage, if the current set <m>S_i</m> is not a basis of <m>W</m>, add any element <m>\boldb\notin \Span S_i</m>. Since <m>W\subseteq V</m>, and since <m>\dim V\leq n</m>, the linearly independent sets <m>S_i</m> cannot have more than <m>n</m> elements; thus the procedure must halt with a basis <m>B</m> of <m>W</m> satisfying <m>\val{B}\leq n</m>. We conclude that <m>\dim W\leq \dim V</m>.
          </p>
        </li>
        <li>
          <p>
            Clearly, if <m>W=V</m>, then <m>\dim W=\dim V</m>. For the other direction, assume <m>\dim W=\dim V=n</m>. Let <m>B</m> be a basis for <m>W</m>. Since <m>B</m> is lienarly independent, it can be extended to a basis <m>B'</m> of <m>V</m> (<xref ref="th_basis_contract_expand" text="global"/>). Since <m>\val{B}=\dim W=\dim V</m>, and since all bases of <m>V</m> have cardinality <m>n</m>, we must have <m>B=B'</m>. It follows that <m>B</m> is also a basis of <m>V</m>, and hence that
            <me>
              V=\Span B=W
            </me>.
          </p>
        </li>
      </ol>
    </p>
  </proof>

</corollary>
That was quite a dose of theory! For your convenience, we collect the various results on dimension, together with their nicknames, in one omnibus theorem.
<theorem xml:id="th_dimension_compendium">
  <title>Dimension theory compendium</title>
  <statement>
    <p>
    Let <m>V</m> be a vector space of dimension <m>n</m>.
    </p>
    <ol>
      <li>
        <title>Contract</title>
        <p>
        If <m>S</m> spans <m>V</m>, then <m>S</m> can be contracted to a basis of <m>V</m>.
        </p>
      </li>
      <li>
        <title>Expand</title>
        <p>
        If <m>S</m> is linearly independent, then <m>S</m> can be extended to a basis of <m>V</m>.
        </p>
      </li>
      <li>
        <title>Street smarts</title>
        <p>
        If <m>S\subseteq V</m> and <m>\val{S} &lt; n</m>, then <m>S</m> does not span <m>V</m>.
        </p>
      </li>
      <li>
        <title>Street smarts</title>
        <p>
        If <m>S\subseteq V</m> and <m>\val{S} > n</m>, then <m>S</m> is linearly dependent.
        </p>
      </li>
      <li>
        <title>Street smarts</title>
        <p>
          If <m>S\subseteq V</m> and <m>\val{S}=n</m>, then <m>S</m> is a basis if and only if <m>S</m> spans if and only if <m>S</m> is linearly independent.
        </p>
      </li>
      <li>
        <title>Dimension of subspaces</title>
        <p>
        If <m>W\subseteq V</m> is a subspace, then
        <ol>
          <li>
            <p>
              <m>\dim W\leq \dim V</m>, and
            </p>
          </li>
          <li>
            <p>
              <m>\dim W=\dim V</m> if and only if <m>W=V</m>.
            </p>
          </li>
        </ol>
        </p>
      </li>

    </ol>
  </statement>
</theorem>

</subsection>
<xi:include href="./s_basis_dimension_ex.ptx"/>
</section>
